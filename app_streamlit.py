import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import base64
import json
import os
from fingerprint.preprocessor import preprocess_image
from fingerprint.feature_extractor import extract_features, match_features, detect_minutiae
from fingerprint.quality import calculate_quality
import gc
import pandas as pd

# ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© (Ø¨Ø§Ù„Ø¨Ø§ÙŠØª)
MAX_IMAGE_SIZE = 8 * 1024 * 1024  # 8MB

def process_image_stages(image_file):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¹Ø¨Ø± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø±Ø§Ø­Ù„"""
    stages = {}
    
    try:
        # ØªØ­ÙˆÙŠÙ„ Ù…Ù„Ù Streamlit Ø¥Ù„Ù‰ ØµÙˆØ±Ø© OpenCV
        file_bytes = np.asarray(bytearray(image_file.read()), dtype=np.uint8)
        img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
        
        if img is None:
            return stages
            
        # ğŸ–¼ï¸ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©..."):
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¨Ø§ÙŠÙ†
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            
            # ØªØ®ÙÙŠÙ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
            denoised = cv2.fastNlMeansDenoising(enhanced)
            
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­ÙˆØ§Ù
            edges = cv2.Canny(denoised, 100, 200)
            
            stages['processed'] = denoised
            stages['edges'] = edges
        
        # ğŸ“ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù…Ø§Øª
        if 'processed' in stages:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù…Ø§Øª..."):
                features = extract_features(stages['processed'])
                if features is not None:
                    stages['features'] = features
        
        # ğŸ“ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø­ÙØ¸ Ø§Ù„Ø³Ù…Ø§Øª
        if 'features' in stages:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø­ÙØ¸ Ø§Ù„Ø³Ù…Ø§Øª..."):
                filename = f"features_{hash(str(image_file.name))}.json"
                save_features_to_json(stages['features'], filename)
                stages['saved_features'] = filename
        
        return stages
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {str(e)}")
        return stages

def save_features_to_json(features, filename):
    """Ø­ÙØ¸ Ø§Ù„Ø³Ù…Ø§Øª Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON"""
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ†ØªÙˆØ±Ø§Øª Ø¥Ù„Ù‰ Ù‚ÙˆØ§Ø¦Ù…
    minutiae_data = {}
    for type_name, contours in features['minutiae'].items():
        minutiae_data[type_name] = []
        for contour in contours:
            M = cv2.moments(contour)
            if M["m00"] != 0:
                cX = int(M["m10"] / M["m00"])
                cY = int(M["m01"] / M["m00"])
                minutiae_data[type_name].append({
                    'x': cX,
                    'y': cY,
                    'type': type_name
                })
    
    # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    with open(filename, 'w') as f:
        json.dump(minutiae_data, f)

def draw_minutiae_with_matches(image, features, matches=None, other_image=None):
    """Ø±Ø³Ù… Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø© Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø®Ø·ÙˆØ· Ø§Ù„ØªØ·Ø§Ø¨Ù‚"""
    if features is None or 'minutiae' not in features:
        return image
        
    # Ù†Ø³Ø® Ø§Ù„ØµÙˆØ±Ø©
    img_with_minutiae = image.copy()
    
    # Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©
    colors = {
        'ridge_endings': (0, 255, 0),    # Ø£Ø®Ø¶Ø±
        'bifurcations': (255, 0, 0),     # Ø£Ø²Ø±Ù‚
        'islands': (0, 0, 255),          # Ø£Ø­Ù…Ø±
        'dots': (255, 255, 0),           # Ø£ØµÙØ±
        'cores': (255, 0, 255),          # ÙˆØ±Ø¯ÙŠ
        'deltas': (0, 255, 255)          # Ø³Ù…Ø§ÙˆÙŠ
    }
    
    # Ø±Ø³Ù… Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©
    for minutiae_type, contours in features['minutiae'].items():
        color = colors[minutiae_type]
        for contour in contours:
            try:
                # Ø±Ø³Ù… Ø§Ù„ÙƒÙ†ØªÙˆØ±
                cv2.drawContours(img_with_minutiae, [contour], -1, color, 2)
                
                # Ø±Ø³Ù… Ù…Ø±ÙƒØ² Ø§Ù„ÙƒØªÙ„Ø©
                M = cv2.moments(contour)
                if M["m00"] != 0:
                    cX = int(M["m10"] / M["m00"])
                    cY = int(M["m01"] / M["m00"])
                    
                    # Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±Ø© Ø­ÙˆÙ„ Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ù…Ù…ÙŠØ²Ø©
                    cv2.circle(img_with_minutiae, (cX, cY), 8, color, -1)
                    
                    # Ø±Ø³Ù… Ø±Ù‚Ù… Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ù…Ù…ÙŠØ²Ø©
                    cv2.putText(img_with_minutiae, str(len(features['minutiae'][minutiae_type])), 
                              (cX-10, cY-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
            except:
                continue
    
    # Ø±Ø³Ù… Ø®Ø·ÙˆØ· Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ ØªØ·Ø§Ø¨Ù‚Ø§Øª
    if matches is not None and other_image is not None:
        for i, match in enumerate(matches):
            try:
                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…ØªØ·Ø§Ø¨Ù‚Ø©
                pt1 = (int(match[0][0]), int(match[0][1]))
                pt2 = (int(match[1][0]), int(match[1][1]))
                
                # Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±Ø© Ø­ÙˆÙ„ Ø§Ù„Ù†Ù‚Ø·Ø© ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
                cv2.circle(img_with_minutiae, pt1, 10, (0, 255, 255), 2)
                
                # Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±Ø© Ø­ÙˆÙ„ Ø§Ù„Ù†Ù‚Ø·Ø© ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©
                cv2.circle(other_image, pt2, 10, (0, 255, 255), 2)
                
                # Ø±Ø³Ù… Ø®Ø· Ø§Ù„ØªØ·Ø§Ø¨Ù‚
                cv2.line(img_with_minutiae, pt1, pt2, (0, 255, 255), 2)
                
                # Ø±Ø³Ù… Ø±Ù‚Ù… Ø§Ù„ØªØ·Ø§Ø¨Ù‚
                cv2.putText(img_with_minutiae, str(i+1), 
                          (pt1[0]-10, pt1[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
                cv2.putText(other_image, str(i+1), 
                          (pt2[0]-10, pt2[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
            except:
                continue
    
    return img_with_minutiae

def show_minutiae_details(features):
    """Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©"""
    if features is None or 'minutiae' not in features:
        return
        
    # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©
    st.markdown("#### Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©")
    stats = {
        'Ù†Ù‡Ø§ÙŠØ© Ù†ØªÙˆØ¡': len(features['minutiae'].get('ridge_endings', [])),
        'ØªÙØ±Ø¹': len(features['minutiae'].get('bifurcations', [])),
        'Ø¬Ø²ÙŠØ±Ø©': len(features['minutiae'].get('islands', [])),
        'Ù†Ù‚Ø·Ø©': len(features['minutiae'].get('dots', [])),
        'Ù†ÙˆØ§Ø©': len(features['minutiae'].get('cores', [])),
        'Ø¯Ù„ØªØ§': len(features['minutiae'].get('deltas', []))
    }
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Ù†Ù‡Ø§ÙŠØ§Øª Ø§Ù„Ù†ØªÙˆØ¡Ø§Øª", stats['Ù†Ù‡Ø§ÙŠØ© Ù†ØªÙˆØ¡'])
        st.metric("Ø§Ù„ØªÙØ±Ø¹Ø§Øª", stats['ØªÙØ±Ø¹'])
    with col2:
        st.metric("Ø§Ù„Ø¬Ø²Ø±", stats['Ø¬Ø²ÙŠØ±Ø©'])
        st.metric("Ø§Ù„Ù†Ù‚Ø§Ø·", stats['Ù†Ù‚Ø·Ø©'])
    with col3:
        st.metric("Ø§Ù„Ù†ÙˆÙ‰", stats['Ù†ÙˆØ§Ø©'])
        st.metric("Ø§Ù„Ø¯Ù„ØªØ§", stats['Ø¯Ù„ØªØ§'])

def main():
    st.set_page_config(
        page_title="Ù†Ø¸Ø§Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµÙ…Ø§Øª",
        page_icon="ğŸ‘†",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ØªÙ†Ø³ÙŠÙ‚ CSS Ù…Ø®ØµØµ
    st.markdown("""
        <style>
        .main {
            background-color: #f8f9fa;
        }
        .stApp {
            max-width: 1200px;
            margin: 0 auto;
        }
        .title-text {
            color: #2c3e50;
            font-size: 2.5rem;
            font-weight: bold;
            text-align: center;
            margin-bottom: 2rem;
        }
        .upload-box {
            background-color: white;
            padding: 2rem;
            border-radius: 15px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin-bottom: 2rem;
        }
        .result-box {
            background-color: white;
            padding: 2rem;
            border-radius: 15px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin-top: 2rem;
        }
        .stage-container {
            padding: 1rem;
            margin: 1rem 0;
            border-radius: 10px;
            background-color: #f8f9fa;
        }
        .stage-title {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 1rem;
        }
        .stage-icon {
            font-size: 1.5rem;
        }
        .quality-score {
            font-size: 1.2rem;
            color: #2c3e50;
            margin-bottom: 1rem;
        }
        .match-score {
            font-size: 1.5rem;
            font-weight: bold;
            color: #27ae60;
            margin: 1rem 0;
        }
        .match-result {
            font-size: 1.2rem;
            font-weight: bold;
            text-align: center;
            padding: 1rem;
            border-radius: 10px;
            margin-top: 1rem;
        }
        .match-result.match {
            background-color: #2ecc71;
            color: white;
        }
        .match-result.no-match {
            background-color: #e74c3c;
            color: white;
        }
        .stButton>button {
            width: 100%;
            background-color: #3498db;
            color: white;
            border: none;
            padding: 1rem;
            border-radius: 10px;
            font-weight: bold;
            transition: background-color 0.3s;
        }
        .stButton>button:hover {
            background-color: #2980b9;
        }
        .image-container {
            display: flex;
            justify-content: center;
            align-items: center;
            margin: 1rem 0;
        }
        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .minutiae-legend {
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
            margin: 1rem 0;
        }
        .minutiae-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        .minutiae-color {
            width: 20px;
            height: 20px;
            border-radius: 50%;
        }
        </style>
    """, unsafe_allow_html=True)
    
    st.markdown('<h1 class="title-text">Ù†Ø¸Ø§Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµÙ…Ø§Øª</h1>', unsafe_allow_html=True)
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±
    st.markdown("### ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ØµÙ…Ø§Øª")
    uploaded_files = st.file_uploader("Ø§Ø®ØªØ± Ø§Ù„Ø¨ØµÙ…Ø§Øª Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)
    
    if st.button("Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"):
        if uploaded_files and len(uploaded_files) >= 2:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø¨ØµÙ…Ø©
            processed_stages = []
            for file in uploaded_files:
                # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ù…Ø¤Ø´Ø± Ø§Ù„Ù…Ù„Ù
                file.seek(0)
                stages = process_image_stages(file)
                processed_stages.append(stages)
            
            # Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ ÙƒÙ„ Ù…Ø±Ø­Ù„Ø©
            for i, stages in enumerate(processed_stages):
                st.markdown(f'<div class="stage-container">', unsafe_allow_html=True)
                st.markdown(f'<h3>Ø§Ù„Ø¨ØµÙ…Ø© {i+1}</h3>', unsafe_allow_html=True)
                
                # ğŸ–¼ï¸ Ø¹Ø±Ø¶ Ù…Ø±Ø­Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
                if 'processed' in stages:
                    st.markdown('<div class="stage-title"><span class="stage-icon">ğŸ–¼ï¸</span> Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©</div>', unsafe_allow_html=True)
                    st.image(stages['processed'], use_container_width=True)
                    
                    if 'edges' in stages:
                        st.markdown("#### Ø­ÙˆØ§Ù Ø§Ù„Ø¨ØµÙ…Ø©")
                        st.image(stages['edges'], use_container_width=True)
                
                # ğŸ“ Ø¹Ø±Ø¶ Ù…Ø±Ø­Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù…Ø§Øª
                if 'features' in stages:
                    st.markdown('<div class="stage-title"><span class="stage-icon">ğŸ“</span> Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù…Ø§Øª</div>', unsafe_allow_html=True)
                    img_with_minutiae = draw_minutiae_with_matches(stages['processed'], stages['features'])
                    st.image(img_with_minutiae, use_container_width=True)
                    
                    # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø³Ù…Ø§Øª
                    show_minutiae_details(stages['features'])
                
                # ğŸ“ Ø¹Ø±Ø¶ Ù…Ø±Ø­Ù„Ø© Ø­ÙØ¸ Ø§Ù„Ø³Ù…Ø§Øª
                if 'saved_features' in stages:
                    st.markdown('<div class="stage-title"><span class="stage-icon">ğŸ“</span> Ø­ÙØ¸ Ø§Ù„Ø³Ù…Ø§Øª</div>', unsafe_allow_html=True)
                    st.markdown(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø³Ù…Ø§Øª ÙÙŠ Ø§Ù„Ù…Ù„Ù: `{stages['saved_features']}`")
                
                st.markdown('</div>', unsafe_allow_html=True)
            
            # ğŸ” Ø¹Ø±Ø¶ Ù…Ø±Ø­Ù„Ø© Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¨ØµÙ…Ø§Øª
            st.markdown('<div class="stage-container">', unsafe_allow_html=True)
            st.markdown('<div class="stage-title"><span class="stage-icon">ğŸ”</span> Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¨ØµÙ…Ø§Øª</div>', unsafe_allow_html=True)
            
            for i in range(len(processed_stages)):
                for j in range(i+1, len(processed_stages)):
                    if 'features' in processed_stages[i] and 'features' in processed_stages[j]:
                        st.markdown(f"#### Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµÙ…Ø© {i+1} Ù…Ø¹ Ø§Ù„Ø¨ØµÙ…Ø© {j+1}")
                        
                        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ·Ø§Ø¨Ù‚
                        match_score, matches = match_features(
                            processed_stages[i]['features'],
                            processed_stages[j]['features']
                        )
                        
                        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                        st.markdown('<div class="match-info">', unsafe_allow_html=True)
                        st.markdown(f"Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚: {match_score:.2f}%")
                        st.markdown(f"Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…ØªØ·Ø§Ø¨Ù‚Ø©: {len(matches)}")
                        
                        if match_score > 80:
                            st.markdown('<div class="match-result match">Ø§Ù„Ø¨ØµÙ…ØªØ§Ù† Ù…ØªØ·Ø§Ø¨Ù‚ØªØ§Ù†</div>', unsafe_allow_html=True)
                        else:
                            st.markdown('<div class="match-result no-match">Ø§Ù„Ø¨ØµÙ…ØªØ§Ù† ØºÙŠØ± Ù…ØªØ·Ø§Ø¨Ù‚ØªÙŠÙ†</div>', unsafe_allow_html=True)
                        
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± Ù…Ø¹ Ø®Ø·ÙˆØ· Ø§Ù„ØªØ·Ø§Ø¨Ù‚
                        col1, col2 = st.columns(2)
                        with col1:
                            img1_with_matches = draw_minutiae_with_matches(
                                processed_stages[i]['processed'],
                                processed_stages[i]['features'],
                                matches,
                                processed_stages[j]['processed']
                            )
                            st.image(img1_with_matches, caption=f"Ø§Ù„Ø¨ØµÙ…Ø© {i+1}", use_container_width=True)
                        
                        with col2:
                            img2_with_matches = draw_minutiae_with_matches(
                                processed_stages[j]['processed'],
                                processed_stages[j]['features'],
                                matches,
                                processed_stages[i]['processed']
                            )
                            st.image(img2_with_matches, caption=f"Ø§Ù„Ø¨ØµÙ…Ø© {j+1}", use_container_width=True)
            
            st.markdown('</div>', unsafe_allow_html=True)
            
            # ğŸ“Š Ø¹Ø±Ø¶ Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
            st.markdown('<div class="stage-container">', unsafe_allow_html=True)
            st.markdown('<div class="stage-title"><span class="stage-icon">ğŸ“Š</span> Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª</div>', unsafe_allow_html=True)
            
            # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
            total_minutiae = sum(len(stages.get('features', {}).get('minutiae', {}).get(type_name, [])) 
                               for stages in processed_stages 
                               for type_name in ['ridge_endings', 'bifurcations', 'islands', 'dots', 'cores', 'deltas'])
            
            st.markdown(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©: {total_minutiae}")
            
            # Ø¹Ø±Ø¶ Ø¬ÙˆØ¯Ø© ÙƒÙ„ Ø¨ØµÙ…Ø©
            for i, stages in enumerate(processed_stages):
                if 'processed' in stages:
                    quality = calculate_quality(stages['processed'])
                    st.markdown(f"Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ØµÙ…Ø© {i+1}: {quality:.2f}%")
            
            st.markdown('</div>', unsafe_allow_html=True)
            
        else:
            st.error("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ø¨ØµÙ…ØªÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©")
    
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
    st.header("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…")
    st.markdown("""
    - ÙŠØ¯Ø¹Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ØµÙ…Ø§Øª Ø§Ù„Ø£ØµØ§Ø¨Ø¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
    - ÙŠÙ…ÙƒÙ† ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø¨ØµÙŠØº PNG, JPG, JPEG
    - ÙŠØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù„ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    - ÙŠØ¹Ø±Ø¶ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø© ÙˆØ®Ø·ÙˆØ· Ø§Ù„ØªØ·Ø§Ø¨Ù‚
    - ÙŠØ­Ø³Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø¨ØµÙ…Ø§Øª
    - ÙŠØ¯Ø¹Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø£ÙƒØ«Ø± Ù…Ù† Ø¨ØµÙ…ØªÙŠÙ† ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª
    - ÙŠØ­ÙØ¸ Ø§Ù„Ø³Ù…Ø§Øª ÙÙŠ Ù…Ù„ÙØ§Øª JSON Ù„Ù„Ø±Ø¬ÙˆØ¹ Ø¥Ù„ÙŠÙ‡Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹
    """)

if __name__ == "__main__":
    main() 