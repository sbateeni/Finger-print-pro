import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import base64
import json
import os
from fingerprint.preprocessor import preprocess_image
from fingerprint.feature_extractor import extract_features, match_features
from fingerprint.quality import calculate_quality
from fingerprint.analyzer import show_advanced_analysis
from fingerprint.matcher import show_matching_results
import gc
import pandas as pd
import matplotlib.pyplot as plt

# ØªØ¹ÙŠÙŠÙ† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="Ù†Ø¸Ø§Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµÙ…Ø§Øª",
    page_icon="ğŸ‘†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True)

# ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© (Ø¨Ø§Ù„Ø¨Ø§ÙŠØª)
MAX_IMAGE_SIZE = 8 * 1024 * 1024  # 8MB

def process_image_stages(image_file):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¹Ø¨Ø± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø±Ø§Ø­Ù„"""
    stages = {}
    
    try:
        # ØªØ­ÙˆÙŠÙ„ Ù…Ù„Ù Streamlit Ø¥Ù„Ù‰ ØµÙˆØ±Ø© OpenCV
        file_bytes = np.asarray(bytearray(image_file.read()), dtype=np.uint8)
        img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
        
        if img is None:
            return stages
            
        # ğŸ–¼ï¸ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©..."):
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¨Ø§ÙŠÙ†
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            
            # ØªØ®ÙÙŠÙ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
            denoised = cv2.fastNlMeansDenoising(enhanced)
            
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­ÙˆØ§Ù
            edges = cv2.Canny(denoised, 100, 200)
            
            stages['processed'] = denoised
            stages['edges'] = edges
        
        # ğŸ“ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù…Ø§Øª
        if 'processed' in stages:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù…Ø§Øª..."):
                features = extract_features(stages['processed'])
                if features is not None:
                    stages['features'] = features
        
        # ğŸ“ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø­ÙØ¸ Ø§Ù„Ø³Ù…Ø§Øª
        if 'features' in stages:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø­ÙØ¸ Ø§Ù„Ø³Ù…Ø§Øª..."):
                filename = os.path.join(DATA_DIR, f"features_{hash(str(image_file.name))}.json")
                save_features_to_json(stages['features'], filename)
                stages['saved_features'] = filename
        
        return stages
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {str(e)}")
        return stages

def save_features_to_json(features, filename):
    """Ø­ÙØ¸ Ø§Ù„Ø³Ù…Ø§Øª Ø¨ØªÙ†Ø³ÙŠÙ‚ JSON"""
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ†ØªÙˆØ±Ø§Øª Ø¥Ù„Ù‰ Ù‚ÙˆØ§Ø¦Ù…
    minutiae_data = {}
    for type_name, contours in features['minutiae'].items():
        minutiae_data[type_name] = []
        for contour in contours:
            M = cv2.moments(contour)
            if M["m00"] != 0:
                cX = int(M["m10"] / M["m00"])
                cY = int(M["m01"] / M["m00"])
                minutiae_data[type_name].append({
                    'x': cX,
                    'y': cY,
                    'type': type_name
                })
    
    # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    with open(filename, 'w') as f:
        json.dump(minutiae_data, f)

def draw_minutiae_with_matches(image, features, matches=None, other_image=None):
    """Ø±Ø³Ù… Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø© Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø®Ø·ÙˆØ· Ø§Ù„ØªØ·Ø§Ø¨Ù‚"""
    if features is None or 'minutiae' not in features:
        return image
        
    # Ù†Ø³Ø® Ø§Ù„ØµÙˆØ±Ø©
    img_with_minutiae = image.copy()
    
    # Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©
    colors = {
        'ridge_endings': (0, 255, 0),    # Ø£Ø®Ø¶Ø±
        'bifurcations': (255, 0, 0),     # Ø£Ø²Ø±Ù‚
        'islands': (0, 0, 255),          # Ø£Ø­Ù…Ø±
        'dots': (255, 255, 0),           # Ø£ØµÙØ±
        'cores': (255, 0, 255),          # ÙˆØ±Ø¯ÙŠ
        'deltas': (0, 255, 255)          # Ø³Ù…Ø§ÙˆÙŠ
    }
    
    # Ø±Ø³Ù… Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©
    for minutiae_type, contours in features['minutiae'].items():
        color = colors[minutiae_type]
        for contour in contours:
            try:
                # Ø±Ø³Ù… Ø§Ù„ÙƒÙ†ØªÙˆØ±
                cv2.drawContours(img_with_minutiae, [contour], -1, color, 2)
                
                # Ø±Ø³Ù… Ù…Ø±ÙƒØ² Ø§Ù„ÙƒØªÙ„Ø©
                M = cv2.moments(contour)
                if M["m00"] != 0:
                    cX = int(M["m10"] / M["m00"])
                    cY = int(M["m01"] / M["m00"])
                    
                    # Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±Ø© Ø­ÙˆÙ„ Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ù…Ù…ÙŠØ²Ø©
                    cv2.circle(img_with_minutiae, (cX, cY), 8, color, -1)
                    
                    # Ø±Ø³Ù… Ø±Ù‚Ù… Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ù…Ù…ÙŠØ²Ø©
                    cv2.putText(img_with_minutiae, str(len(features['minutiae'][minutiae_type])), 
                              (cX-10, cY-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
            except:
                continue
    
    # Ø±Ø³Ù… Ø®Ø·ÙˆØ· Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ ØªØ·Ø§Ø¨Ù‚Ø§Øª
    if matches is not None and other_image is not None:
        for i, match in enumerate(matches):
            try:
                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…ØªØ·Ø§Ø¨Ù‚Ø©
                pt1 = (int(match[0][0]), int(match[0][1]))
                pt2 = (int(match[1][0]), int(match[1][1]))
                
                # Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±Ø© Ø­ÙˆÙ„ Ø§Ù„Ù†Ù‚Ø·Ø© ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
                cv2.circle(img_with_minutiae, pt1, 10, (0, 255, 255), 2)
                
                # Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±Ø© Ø­ÙˆÙ„ Ø§Ù„Ù†Ù‚Ø·Ø© ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©
                cv2.circle(other_image, pt2, 10, (0, 255, 255), 2)
                
                # Ø±Ø³Ù… Ø®Ø· Ø§Ù„ØªØ·Ø§Ø¨Ù‚
                cv2.line(img_with_minutiae, pt1, pt2, (0, 255, 255), 2)
                
                # Ø±Ø³Ù… Ø±Ù‚Ù… Ø§Ù„ØªØ·Ø§Ø¨Ù‚
                cv2.putText(img_with_minutiae, str(i+1), 
                          (pt1[0]-10, pt1[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
                cv2.putText(other_image, str(i+1), 
                          (pt2[0]-10, pt2[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
            except:
                continue
    
    return img_with_minutiae

def show_minutiae_details(features):
    """Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©"""
    if features is None or 'minutiae' not in features:
        return
        
    # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©
    st.markdown("#### Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©")
    stats = {
        'Ù†Ù‡Ø§ÙŠØ© Ù†ØªÙˆØ¡': len(features['minutiae'].get('ridge_endings', [])),
        'ØªÙØ±Ø¹': len(features['minutiae'].get('bifurcations', [])),
        'Ø¬Ø²ÙŠØ±Ø©': len(features['minutiae'].get('islands', [])),
        'Ù†Ù‚Ø·Ø©': len(features['minutiae'].get('dots', [])),
        'Ù†ÙˆØ§Ø©': len(features['minutiae'].get('cores', [])),
        'Ø¯Ù„ØªØ§': len(features['minutiae'].get('deltas', []))
    }
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Ù†Ù‡Ø§ÙŠØ§Øª Ø§Ù„Ù†ØªÙˆØ¡Ø§Øª", stats['Ù†Ù‡Ø§ÙŠØ© Ù†ØªÙˆØ¡'])
        st.metric("Ø§Ù„ØªÙØ±Ø¹Ø§Øª", stats['ØªÙØ±Ø¹'])
    with col2:
        st.metric("Ø§Ù„Ø¬Ø²Ø±", stats['Ø¬Ø²ÙŠØ±Ø©'])
        st.metric("Ø§Ù„Ù†Ù‚Ø§Ø·", stats['Ù†Ù‚Ø·Ø©'])
    with col3:
        st.metric("Ø§Ù„Ù†ÙˆÙ‰", stats['Ù†ÙˆØ§Ø©'])
        st.metric("Ø§Ù„Ø¯Ù„ØªØ§", stats['Ø¯Ù„ØªØ§'])

def analyze_fingerprint_details(image, features):
    """ØªØ­Ù„ÙŠÙ„ ØªÙØµÙŠÙ„ÙŠ Ù„Ù„Ø¨ØµÙ…Ø©"""
    details = {}
    
    try:
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ±Ø¯Ø¯Ø§Øª
        fft = np.fft.fft2(image)
        fft_shift = np.fft.fftshift(fft)
        magnitude_spectrum = 20 * np.log(np.abs(fft_shift) + 1)
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø¥Ù„Ù‰ Ù†Ø·Ø§Ù‚ [0, 1]
        magnitude_spectrum = (magnitude_spectrum - magnitude_spectrum.min()) / (magnitude_spectrum.max() - magnitude_spectrum.min())
        details['frequency_analysis'] = magnitude_spectrum
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª
        if 'minutiae' in features:
            directions = []
            for type_name, contours in features['minutiae'].items():
                for contour in contours:
                    try:
                        if len(contour) >= 5:
                            ellipse = cv2.fitEllipse(contour)
                            directions.append(ellipse[2])
                    except:
                        continue
            details['directions'] = directions
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©
        minutiae_stats = {}
        for type_name, contours in features.get('minutiae', {}).items():
            minutiae_stats[type_name] = {
                'count': len(contours),
                'areas': [cv2.contourArea(c) for c in contours],
                'perimeters': [cv2.arcLength(c, True) for c in contours]
            }
        details['minutiae_stats'] = minutiae_stats
        
        # ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©
        details['quality_metrics'] = {
            'contrast': np.std(image),
            'brightness': np.mean(image),
            'sharpness': cv2.Laplacian(image, cv2.CV_64F).var()
        }
        
        return details
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ØµÙ…Ø©: {str(e)}")
        return details

def create_advanced_matching_image(image1, image2, features1, features2, matches):
    """Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©"""
    # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© ØªØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ø¨ØµÙ…ØªÙŠÙ†
    h1, w1 = image1.shape[:2]
    h2, w2 = image2.shape[:2]
    max_h = max(h1, h2)
    total_w = w1 + w2
    matching_image = np.zeros((max_h, total_w, 3), dtype=np.uint8)
    
    # ÙˆØ¶Ø¹ Ø§Ù„Ø¨ØµÙ…ØªÙŠÙ† ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©
    matching_image[:h1, :w1] = cv2.cvtColor(image1, cv2.COLOR_GRAY2BGR)
    matching_image[:h2, w1:] = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)
    
    # Ø±Ø³Ù… Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©
    colors = {
        'ridge_endings': (0, 255, 0),    # Ø£Ø®Ø¶Ø±
        'bifurcations': (255, 0, 0),     # Ø£Ø²Ø±Ù‚
        'islands': (0, 0, 255),          # Ø£Ø­Ù…Ø±
        'dots': (255, 255, 0),           # Ø£ØµÙØ±
        'cores': (255, 0, 255),          # ÙˆØ±Ø¯ÙŠ
        'deltas': (0, 255, 255)          # Ø³Ù…Ø§ÙˆÙŠ
    }
    
    # Ø±Ø³Ù… Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø© Ù„Ù„Ø¨ØµÙ…Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
    for type_name, contours in features1.get('minutiae', {}).items():
        color = colors[type_name]
        for contour in contours:
            try:
                cv2.drawContours(matching_image, [contour], -1, color, 2)
                M = cv2.moments(contour)
                if M["m00"] != 0:
                    cX = int(M["m10"] / M["m00"])
                    cY = int(M["m01"] / M["m00"])
                    cv2.circle(matching_image, (cX, cY), 5, color, -1)
            except:
                continue
    
    # Ø±Ø³Ù… Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø© Ù„Ù„Ø¨ØµÙ…Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©
    for type_name, contours in features2.get('minutiae', {}).items():
        color = colors[type_name]
        for contour in contours:
            try:
                contour_shifted = contour + np.array([w1, 0])
                cv2.drawContours(matching_image, [contour_shifted], -1, color, 2)
                M = cv2.moments(contour)
                if M["m00"] != 0:
                    cX = int(M["m10"] / M["m00"]) + w1
                    cY = int(M["m01"] / M["m00"])
                    cv2.circle(matching_image, (cX, cY), 5, color, -1)
            except:
                continue
    
    # Ø±Ø³Ù… Ø®Ø·ÙˆØ· Ø§Ù„ØªØ·Ø§Ø¨Ù‚
    for i, match in enumerate(matches):
        try:
            pt1 = (int(match[0][0]), int(match[0][1]))
            pt2 = (int(match[1][0]) + w1, int(match[1][1]))
            
            # Ø±Ø³Ù… Ø¯Ø§Ø¦Ø±Ø© Ø­ÙˆÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…ØªØ·Ø§Ø¨Ù‚Ø©
            cv2.circle(matching_image, pt1, 8, (0, 255, 255), 2)
            cv2.circle(matching_image, pt2, 8, (0, 255, 255), 2)
            
            # Ø±Ø³Ù… Ø®Ø· Ø§Ù„ØªØ·Ø§Ø¨Ù‚
            cv2.line(matching_image, pt1, pt2, (0, 255, 255), 2)
            
            # Ø±Ø³Ù… Ø±Ù‚Ù… Ø§Ù„ØªØ·Ø§Ø¨Ù‚
            cv2.putText(matching_image, str(i+1), 
                       (pt1[0]-10, pt1[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
            cv2.putText(matching_image, str(i+1), 
                       (pt2[0]-10, pt2[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
        except:
            continue
    
    return matching_image

def show_advanced_analysis(stages):
    """Ø¹Ø±Ø¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø¨ØµÙ…Ø©"""
    if 'processed' in stages and 'features' in stages:
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ØµÙ…Ø©
        details = analyze_fingerprint_details(stages['processed'], stages['features'])
        
        # Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        st.markdown("### Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø¨ØµÙ…Ø©")
        
        # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©
        st.markdown("#### Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©")
        minutiae_stats = details.get('minutiae_stats', {})
        for type_name, stats in minutiae_stats.items():
            st.markdown(f"**{type_name}:**")
            st.markdown(f"- Ø§Ù„Ø¹Ø¯Ø¯: {stats['count']}")
            if stats['areas']:
                st.markdown(f"- Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø³Ø§Ø­Ø©: {np.mean(stats['areas']):.2f}")
                st.markdown(f"- Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø­ÙŠØ·: {np.mean(stats['perimeters']):.2f}")
        
        # Ø¹Ø±Ø¶ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©
        st.markdown("#### Ù…Ù‚Ø§ÙŠÙŠØ³ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø©")
        quality_metrics = details.get('quality_metrics', {})
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Ø§Ù„ØªØ¨Ø§ÙŠÙ†", f"{quality_metrics.get('contrast', 0):.2f}")
        with col2:
            st.metric("Ø§Ù„Ø³Ø·ÙˆØ¹", f"{quality_metrics.get('brightness', 0):.2f}")
        with col3:
            st.metric("Ø§Ù„ÙˆØ¶ÙˆØ­", f"{quality_metrics.get('sharpness', 0):.2f}")
        
        # Ø¹Ø±Ø¶ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ±Ø¯Ø¯Ø§Øª
        if 'frequency_analysis' in details:
            st.markdown("#### ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ±Ø¯Ø¯Ø§Øª")
            try:
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø¹Ø±Ø¶
                freq_image = (details['frequency_analysis'] * 255).astype(np.uint8)
                st.image(freq_image, use_container_width=True)
            except Exception as e:
                st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø¹Ø±Ø¶ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ±Ø¯Ø¯Ø§Øª: {str(e)}")
        
        # Ø¹Ø±Ø¶ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª
        if 'directions' in details and details['directions']:
            st.markdown("#### ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª")
            try:
                fig = plt.figure(figsize=(10, 4))
                plt.hist(details['directions'], bins=36, range=(0, 360))
                plt.title("ØªÙˆØ²ÙŠØ¹ Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©")
                plt.xlabel("Ø§Ù„Ø²Ø§ÙˆÙŠØ© (Ø¯Ø±Ø¬Ø©)")
                plt.ylabel("Ø§Ù„Ø¹Ø¯Ø¯")
                st.pyplot(fig)
            except Exception as e:
                st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø¹Ø±Ø¶ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª: {str(e)}")

def main():
    st.markdown("""
        <style>
        .main {
            background-color: #f8f9fa;
        }
        .stApp {
            max-width: 1200px;
            margin: 0 auto;
        }
        .title-text {
            color: #2c3e50;
            font-size: 2.5rem;
            font-weight: bold;
            text-align: center;
            margin-bottom: 2rem;
        }
        .upload-box {
            background-color: white;
            padding: 2rem;
            border-radius: 15px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin-bottom: 2rem;
        }
        .result-box {
            background-color: white;
            padding: 2rem;
            border-radius: 15px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin-top: 2rem;
        }
        .stage-container {
            padding: 1rem;
            margin: 1rem 0;
            border-radius: 10px;
            background-color: #f8f9fa;
        }
        .stage-title {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 1rem;
        }
        .stage-icon {
            font-size: 1.5rem;
        }
        .quality-score {
            font-size: 1.2rem;
            color: #2c3e50;
            margin-bottom: 1rem;
        }
        .match-score {
            font-size: 1.5rem;
            font-weight: bold;
            color: #27ae60;
            margin: 1rem 0;
        }
        .match-result {
            font-size: 1.2rem;
            font-weight: bold;
            text-align: center;
            padding: 1rem;
            border-radius: 10px;
            margin-top: 1rem;
        }
        .match-result.match {
            background-color: #2ecc71;
            color: white;
        }
        .match-result.no-match {
            background-color: #e74c3c;
            color: white;
        }
        .stButton>button {
            width: 100%;
            background-color: #3498db;
            color: white;
            border: none;
            padding: 1rem;
            border-radius: 10px;
            font-weight: bold;
            transition: background-color 0.3s;
        }
        .stButton>button:hover {
            background-color: #2980b9;
        }
        .image-container {
            display: flex;
            justify-content: center;
            align-items: center;
            margin: 1rem 0;
        }
        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .minutiae-legend {
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
            margin: 1rem 0;
        }
        .minutiae-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        .minutiae-color {
            width: 20px;
            height: 20px;
            border-radius: 50%;
        }
        </style>
    """, unsafe_allow_html=True)
    
    st.markdown('<h1 class="title-text">Ù†Ø¸Ø§Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµÙ…Ø§Øª</h1>', unsafe_allow_html=True)
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±
    st.markdown("### ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ØµÙ…Ø§Øª")
    uploaded_files = st.file_uploader("Ø§Ø®ØªØ± Ø§Ù„Ø¨ØµÙ…Ø§Øª Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)
    
    if st.button("Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"):
        if uploaded_files and len(uploaded_files) >= 2:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ„ Ø¨ØµÙ…Ø©
            processed_stages = []
            for file in uploaded_files:
                # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ù…Ø¤Ø´Ø± Ø§Ù„Ù…Ù„Ù
                file.seek(0)
                stages = process_image_stages(file)
                processed_stages.append(stages)
            
            # Ø¹Ø±Ø¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„ÙƒÙ„ Ø¨ØµÙ…Ø©
            for i, stages in enumerate(processed_stages):
                st.markdown(f'<div class="stage-container">', unsafe_allow_html=True)
                st.markdown(f'<h3>Ø§Ù„Ø¨ØµÙ…Ø© {i+1}</h3>', unsafe_allow_html=True)
                
                # Ø¹Ø±Ø¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
                show_advanced_analysis(stages)
                
                st.markdown('</div>', unsafe_allow_html=True)
            
            # Ø¹Ø±Ø¶ Ù…Ù‚Ø§Ø±Ù†Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ø¨ÙŠÙ† Ø§Ù„Ø¨ØµÙ…Ø§Øª
            st.markdown('<div class="stage-container">', unsafe_allow_html=True)
            st.markdown('<div class="stage-title"><span class="stage-icon">ğŸ”</span> Ù…Ù‚Ø§Ø±Ù†Ø© Ù…ØªÙ‚Ø¯Ù…Ø©</div>', unsafe_allow_html=True)
            
            for i in range(len(processed_stages)):
                for j in range(i+1, len(processed_stages)):
                    if 'features' in processed_stages[i] and 'features' in processed_stages[j]:
                        st.markdown(f"#### Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµÙ…Ø© {i+1} Ù…Ø¹ Ø§Ù„Ø¨ØµÙ…Ø© {j+1}")
                        
                        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ·Ø§Ø¨Ù‚
                        match_score, matches = match_features(
                            processed_stages[i]['features'],
                            processed_stages[j]['features']
                        )
                        
                        # Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
                        show_matching_results(
                            processed_stages[i],
                            processed_stages[j],
                            match_score,
                            matches
                        )
            
            st.markdown('</div>', unsafe_allow_html=True)
            
            # ğŸ“Š Ø¹Ø±Ø¶ Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
            st.markdown('<div class="stage-container">', unsafe_allow_html=True)
            st.markdown('<div class="stage-title"><span class="stage-icon">ğŸ“Š</span> Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª</div>', unsafe_allow_html=True)
            
            # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
            total_minutiae = sum(len(stages.get('features', {}).get('minutiae', {}).get(type_name, [])) 
                               for stages in processed_stages 
                               for type_name in ['ridge_endings', 'bifurcations', 'islands', 'dots', 'cores', 'deltas'])
            
            st.markdown(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø©: {total_minutiae}")
            
            # Ø¹Ø±Ø¶ Ø¬ÙˆØ¯Ø© ÙƒÙ„ Ø¨ØµÙ…Ø©
            for i, stages in enumerate(processed_stages):
                if 'processed' in stages:
                    quality = calculate_quality(stages['processed'])
                    st.markdown(f"Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ØµÙ…Ø© {i+1}: {quality:.2f}%")
            
            st.markdown('</div>', unsafe_allow_html=True)
            
        else:
            st.error("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ø¨ØµÙ…ØªÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©")
    
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
    st.header("Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…")
    st.markdown("""
    - ÙŠØ¯Ø¹Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ØµÙ…Ø§Øª Ø§Ù„Ø£ØµØ§Ø¨Ø¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
    - ÙŠÙ…ÙƒÙ† ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø¨ØµÙŠØº PNG, JPG, JPEG
    - ÙŠØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù„ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    - ÙŠØ¹Ø±Ø¶ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø© ÙˆØ®Ø·ÙˆØ· Ø§Ù„ØªØ·Ø§Ø¨Ù‚
    - ÙŠØ­Ø³Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø¨ØµÙ…Ø§Øª
    - ÙŠØ¯Ø¹Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø£ÙƒØ«Ø± Ù…Ù† Ø¨ØµÙ…ØªÙŠÙ† ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª
    - ÙŠØ­ÙØ¸ Ø§Ù„Ø³Ù…Ø§Øª ÙÙŠ Ù…Ù„ÙØ§Øª JSON Ù„Ù„Ø±Ø¬ÙˆØ¹ Ø¥Ù„ÙŠÙ‡Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹
    """)

if __name__ == "__main__":
    main() 